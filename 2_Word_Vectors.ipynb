{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2027d1c3-5434-486b-a9eb-a7c44f87e7dd",
   "metadata": {},
   "source": [
    "# End to end NER with an entity ruler and word vectors\n",
    "1. Document cleaning and splitting the corpus into test and train sets\n",
    "2. Build word vectors\n",
    "3. Build training data with entity ruler and split into train and validation data\n",
    "4. Add word vectors to model, run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b2086-a2a6-4fa9-bf89-059047d9e85f",
   "metadata": {},
   "source": [
    "## Notebook 2\n",
    "- Load training data\n",
    "- Process for word vectors\n",
    "- Build word vectors and save word vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bcd075-4ae1-422e-8d39-2b96ed13fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "import json\n",
    "\n",
    "#tokenize words\n",
    "from gensim.parsing.preprocessing import split_on_space\n",
    "\n",
    "#build n-grams\n",
    "import gensim\n",
    "\n",
    "#build word vectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736f583-1c14-44a2-8217-86b5248446d9",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a18683-7f41-4b32-abd7-faeeb82540cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "def load_data(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8927e1e4-2c70-4e4a-a699-08666befeb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = load_data('data/sw_train_ner.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b56da6-da7d-4724-b99e-0442d0813414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Corran asked', 'necessarily Luke realm possibility either', 'use dueling blasters ranged weapons', 'Usually Deputy Director led morning meetings', 'Wedge gave light slap arm', 'turned Leia', 'Yeah', 'finally caught', 'Kyp put shuttle Corran retrieved extra tool kit pulled shuttle left', '']\n"
     ]
    }
   ],
   "source": [
    "print(files[5:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d8c91-72d8-4829-90f6-9b47cc88732f",
   "metadata": {},
   "source": [
    "### Tokenize sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b92341d-a6ee-46ca-acd7-301757242995",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sentence in files:\n",
    "    sentence = split_on_space(sentence) #tokenizes words\n",
    "    sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5160a11c-af81-498a-ba4b-d259f2a26ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Corran', 'asked'], ['necessarily', 'Luke', 'realm', 'possibility', 'either'], ['use', 'dueling', 'blasters', 'ranged', 'weapons'], ['Usually', 'Deputy', 'Director', 'led', 'morning', 'meetings'], ['Wedge', 'gave', 'light', 'slap', 'arm'], ['turned', 'Leia'], ['Yeah'], ['finally', 'caught'], ['Kyp', 'put', 'shuttle', 'Corran', 'retrieved', 'extra', 'tool', 'kit', 'pulled', 'shuttle', 'left'], []]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[5:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fff6ed-bdaa-40bf-89e5-0fc42f7f9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bigrams\n",
    "#new brigrams becomes input in place of \"final\"\n",
    "bigram_phrases = gensim.models.Phrases(sentences, min_count=5, threshold=50)\n",
    "trigram_phrases = gensim.models.Phrases(bigram_phrases[sentences], min_count=5, threshold=50)\n",
    "\n",
    "bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return([bigram[doc] for doc in texts])\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return([trigram[doc] for doc in texts])\n",
    "\n",
    "data_bigrams = make_bigrams(sentences)\n",
    "data_trigrams = make_trigrams(data_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f22e8c61-1217-4913-abf4-b530fcdadafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['clearly', 'made', 'positive', 'impression', 'least', 'person', 'already'], ['yeah'], ['certainly', 'first'], ['asked', 'date', 'last', 'replacement', 'put', '3', 'ABY']]\n"
     ]
    }
   ],
   "source": [
    "print(data_bigrams[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ea108e-9183-4a07-93cc-77abe9d55218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(file, data):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f)\n",
    "        \n",
    "write_data('./data/training_bigrams.json', data_bigrams)\n",
    "\n",
    "def load_data(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "sentences = load_data('./data/training_bigrams.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d14f3-5684-4dd9-8818-27b7b4a98a89",
   "metadata": {},
   "source": [
    "### Build word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d5cab6b-e7bd-4b3e-b669-189bbf775bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model_name, corpus):\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    w2v_model = Word2Vec(min_count=2, window=2, vector_size=500, sample=6e-5, alpha=.0009, min_alpha=.0007, \n",
    "                         negative=20, workers=cores-1, shrink_windows=True)\n",
    "    w2v_model.build_vocab(corpus)\n",
    "    w2v_model.train(corpus, total_examples=w2v_model.corpus_count, epochs=50)\n",
    "    w2v_model.save(f'word_vectors/{model_name}.model')\n",
    "    w2v_model.wv.save_word2vec_format(f'word_vectors/word2vec_{model_name}.txt')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8325f01e-6bf3-48e9-afbb-0aaeff1ee878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train word vectors\n",
    "training('sw_word_vec_3', sentences) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2deb33c-8de2-40f7-af58-83c5d545b87e",
   "metadata": {},
   "source": [
    "### Use word vectors to review similarity\n",
    "- Adjust model parameters if necessary, and rerun previous two cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87ded32b-fbbb-44ca-b62d-5c911e4044d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_similarity(word):\n",
    "    model = KeyedVectors.load_word2vec_format('./word_vectors/word2vec_sw_word_vec_3.txt', binary=False)\n",
    "    results = model.most_similar(positive=[word])\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2b6cea4-59d5-45a1-b691-e2e9083cf321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Brianna', 0.9993738532066345), ('Wedge', 0.999233067035675), ('people', 0.9992311000823975), ('Jedi', 0.9991311430931091), ('Tycho', 0.9990862607955933), ('Corran', 0.9990518689155579), ('two', 0.9989820718765259), ('another', 0.9989610314369202), ('Iella', 0.9988853931427002), ('Force', 0.998860239982605)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity('Luke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8c20021-9af2-4bbe-80c3-92bd8de18ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Brianna', 0.9989176392555237), ('Luke', 0.9988853931427002), ('Wedge', 0.9988267421722412), ('Jedi', 0.9987472891807556), ('Tycho', 0.9986521005630493), ('people', 0.998629093170166), ('Force', 0.9985208511352539), ('two', 0.9985008239746094), ('Corran', 0.9984903335571289), ('another', 0.9984268546104431)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity('Iella')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f470d366-24cb-4832-a5ba-cf5affef6b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Luke', 0.9993737936019897), ('Wedge', 0.9992231130599976), ('people', 0.999202311038971), ('Tycho', 0.9991704225540161), ('Jedi', 0.9991136789321899), ('Corran', 0.9990859627723694), ('two', 0.9989864826202393), ('another', 0.9989250302314758), ('Iella', 0.9989176988601685), ('small', 0.9988897442817688)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity('Brianna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9fd2813-0a74-44e3-bfd6-14314367f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Luke', 0.9991313219070435), ('Brianna', 0.9991136193275452), ('Wedge', 0.9989767074584961), ('people', 0.998947024345398), ('Corran', 0.9988514184951782), ('Tycho', 0.9988108277320862), ('Iella', 0.9987474083900452), ('two', 0.99871426820755), ('small', 0.9986638426780701), ('another', 0.9986019730567932)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity('Jedi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41aba1c4-43f6-4269-9120-d822323b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Luke', 0.9988601803779602), ('Wedge', 0.998847484588623), ('Brianna', 0.9987767934799194), ('people', 0.998731791973114), ('Tycho', 0.9986791610717773), ('two', 0.9985674619674683), ('Corran', 0.9985648393630981), ('Jedi', 0.9985617399215698), ('Iella', 0.9985208511352539), ('another', 0.998481273651123)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity('Force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3e18dab-cc29-4e37-9fcb-fcaf56c3e66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Luke', 0.9984385371208191), ('Brianna', 0.9984233379364014), ('Tycho', 0.9982741475105286), ('Corran', 0.9982607364654541), ('people', 0.9981838464736938), ('Wedge', 0.9981691241264343), ('another', 0.9980785250663757), ('Jedi', 0.9980262517929077), ('Iella', 0.9979591965675354), ('training', 0.9979300498962402)]\n"
     ]
    }
   ],
   "source": [
    "gen_similarity('lightsaber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4848f46-ce7a-4149-8c61-6dded14df537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
